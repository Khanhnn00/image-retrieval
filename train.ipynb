{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wygIPff43Q89brVbZNEsFJpVEfB1oHOS","authorship_tag":"ABX9TyN1Me0y311m7vd+Rt7IXOOQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtynqRMBQsIe","executionInfo":{"status":"ok","timestamp":1607581315250,"user_tz":-420,"elapsed":1912,"user":{"displayName":"Khanh Nguyen Ngoc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGHlGntxghfhluSmwSsRBdMiXvQJWrGcFCiWNv4A=s64","userId":"00547920197738612963"}},"outputId":"e6fd7bff-79e7-4b60-89c2-b22cba062a2d"},"source":["cd /content/drive/MyDrive/ColabNotebooks/cs336/project/CGD"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/ColabNotebooks/cs336/project/CGD\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ts07DUWEQ2io"},"source":["import os\n","from PIL import Image\n","from scipy.io import loadmat\n","from tqdm import tqdm\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QPtfd870Q3ls","executionInfo":{"status":"ok","timestamp":1607540518374,"user_tz":-420,"elapsed":2948,"user":{"displayName":"Khanh Nguyen Ngoc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGHlGntxghfhluSmwSsRBdMiXvQJWrGcFCiWNv4A=s64","userId":"00547920197738612963"}},"outputId":"c36c419c-3062-4bd3-fd9c-ff7a5e08017a"},"source":["!pip install thop"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: thop in /usr/local/lib/python3.6/dist-packages (0.0.31.post2005241907)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from thop) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wB8XGbCeQ7Am"},"source":["# !python train.py --feature_dim 512 --gd_config SM  --data_path ./dataset --batch_size 16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k0qPLM68VjYm"},"source":["**DEBUG TRAIN.PY**"]},{"cell_type":"code","metadata":{"id":"ix9P8YIJVisV"},"source":["import argparse\n","\n","import pandas as pd\n","import torch\n","from thop import profile, clever_format\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import MultiStepLR\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","from model import Model, set_bn_eval\n","# from utils import recall, LabelSmoothingCrossEntropyLoss, BatchHardTripletLoss, ImageReader, MPerClassSampler\n","from my_utils import recall, LabelSmoothingCrossEntropyLoss, BatchHardTripletLoss, ImageReader, MPerClassSampler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOmjxs0JVrmx"},"source":["data_path = './dataset'\n","data_name = 'vn_food'\n","crop_type = 'uncropped'\n","batch_size = 16\n","backbone_type = 'wide_resnet50_2'\n","gd_config = 'SG'\n","feature_dim = 512\n","num_epochs = 25\n","smoothing = 0.1\n","temperature = 0.5\n","margin = 0.1\n","recalls = 1,2,4,8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLAXcg0ZWUSF"},"source":["def train(net, optim, train_data_loader):\n","    print('starting train...')\n","    net.train()\n","    # fix bn on backbone network\n","    net.apply(set_bn_eval)\n","    total_loss, total_correct, total_num, data_bar = 0, 0, 0, train_data_loader\n","    for inputs, labels in data_bar:\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","        features, classes = net(inputs)\n","        class_loss = class_criterion(classes, labels)\n","        feature_loss = feature_criterion(features, labels)\n","        loss = class_loss + feature_loss\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        pred = torch.argmax(classes, dim=-1)\n","        total_loss += loss.item() * inputs.size(0)\n","        total_correct += torch.sum(pred == labels).item()\n","        total_num += inputs.size(0)\n","        print('Train Epoch {}/{} - Loss:{:.4f} - Acc:{:.2f}%'\n","                                 .format(epoch, num_epochs, total_loss / total_num, total_correct / total_num * 100))\n","\n","    return total_loss / total_num, total_correct / total_num * 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uscxLxcDWU-e"},"source":["def test(net, recall_ids):\n","    net.eval()\n","    with torch.no_grad():\n","        # obtain feature vectors for all data\n","        for key in eval_dict.keys():\n","            eval_dict[key]['features'] = []\n","            for inputs, labels in tqdm(eval_dict[key]['data_loader'], desc='processing {} data'.format(key)):\n","                inputs, labels = inputs.cuda(), labels.cuda()\n","                features, classes = net(inputs)\n","                eval_dict[key]['features'].append(features)\n","            eval_dict[key]['features'] = torch.cat(eval_dict[key]['features'], dim=0)\n","\n","        # compute recall metric\n","        if data_name == 'isc':\n","            acc_list = recall(eval_dict['test']['features'], test_data_set.labels, recall_ids,\n","                              eval_dict['gallery']['features'], gallery_data_set.labels)\n","        else:\n","            acc_list = recall(eval_dict['test']['features'], test_data_set.labels, recall_ids)\n","    desc = 'Test Epoch {}/{} '.format(epoch, num_epochs)\n","    for index, rank_id in enumerate(recall_ids):\n","        desc += 'R@{}:{:.2f}% '.format(rank_id, acc_list[index] * 100)\n","        results['test_recall@{}'.format(rank_id)].append(acc_list[index] * 100)\n","    print(desc)\n","    return acc_list[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zcFhquyqVuGS","executionInfo":{"status":"ok","timestamp":1607540592223,"user_tz":-420,"elapsed":1181,"user":{"displayName":"Khanh Nguyen Ngoc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGHlGntxghfhluSmwSsRBdMiXvQJWrGcFCiWNv4A=s64","userId":"00547920197738612963"}},"outputId":"23674aaa-b2d6-4b3e-b37a-f09ea5485422"},"source":["save_name_pre = '{}_{}_{}_{}_{}_{}_{}_{}_{}'.format(data_name, crop_type, backbone_type, gd_config, feature_dim,\n","                                                    smoothing, temperature, margin, batch_size)\n","\n","results = {'train_loss': [], 'train_accuracy': []}\n","for recall_id in recalls:\n","    results['test_recall@{}'.format(recall_id)] = []\n","train_data_set = ImageReader(data_path, data_name, 'train')\n","train_sample = MPerClassSampler(train_data_set.labels, batch_size)\n","train_data_loader = DataLoader(train_data_set, batch_sampler=train_sample, num_workers=1)\n","test_data_set = ImageReader(data_path, data_name, 'query' if data_name == 'isc' else 'test')\n","test_data_loader = DataLoader(test_data_set, batch_size, shuffle=False, num_workers=8)\n","eval_dict = {'test': {'data_loader': test_data_loader}}\n","\n","# model setup, model profile, optimizer config and loss definition\n","model = Model(backbone_type, gd_config, feature_dim, num_classes=len(train_data_set.class_to_idx)).cuda()\n","flops, params = profile(model, inputs=(torch.randn(1, 3, 224, 224).cuda(),))\n","flops, params = clever_format([flops, params])\n","print('# Model Params: {} FLOPs: {}'.format(params, flops))\n","optimizer = Adam(model.parameters(), lr=1e-4)\n","lr_scheduler = MultiStepLR(optimizer, milestones=[int(0.6 * num_epochs), int(0.8 * num_epochs)], gamma=0.1)\n","class_criterion = LabelSmoothingCrossEntropyLoss(smoothing=smoothing, temperature=temperature)\n","feature_criterion = BatchHardTripletLoss(margin=margin)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'model.GlobalDescriptor'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.ModuleList'>. Treat it as zero Macs and zero Params.\u001b[00m\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'model.L2Norm'>. Treat it as zero Macs and zero Params.\u001b[00m\n","[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'model.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n","# Model Params: 24.05M FLOPs: 10.83G\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RlGs78CrVumQ"},"source":["best_recall = 0.0\n","print(len(train_data_set))\n","for epoch in tqdm(range(1, 25 + 1)):\n","        train_loss, train_accuracy = train(model, optimizer, train_data_loader)\n","        results['train_loss'].append(train_loss)\n","        results['train_accuracy'].append(train_accuracy)\n","        rank = test(model, recalls)\n","        lr_scheduler.step()\n","\n","        # save statistics\n","        #data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n","        #data_frame.to_csv('results/{}_statistics.csv'.format(save_name_pre), index_label='epoch')\n","        # save database and model\n","        data_base = {}\n","        if rank > best_recall:\n","            best_recall = rank\n","            data_base['test_images'] = test_data_set.images\n","            data_base['test_labels'] = test_data_set.labels\n","            data_base['test_features'] = eval_dict['test']['features']\n","            if data_name == 'isc':\n","                data_base['gallery_images'] = gallery_data_set.images\n","                data_base['gallery_labels'] = gallery_data_set.labels\n","                data_base['gallery_features'] = eval_dict['gallery']['features']\n","            torch.save(model.state_dict(), 'results/{}_model.pth'.format(save_name_pre))\n","            print('Model saved at {}'.format(save_name_pre))\n","            torch.save(data_base, 'results/{}_data_base.pth'.format(save_name_pre))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zq8s16ZVO2om"},"source":["**MAKING SOME TESTS**\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6N116hkO5UZ","executionInfo":{"status":"ok","timestamp":1607542651515,"user_tz":-420,"elapsed":6871,"user":{"displayName":"Khanh Nguyen Ngoc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGHlGntxghfhluSmwSsRBdMiXvQJWrGcFCiWNv4A=s64","userId":"00547920197738612963"}},"outputId":"2089d8ad-5e96-46fa-f0d5-6f5740db6368"},"source":["!python test.py --retrieval_num 7 --query_img_name ./dataset/vn_food/test/4.png --data_base vn_food_database.pth"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./dataset/vn_food/test/22.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(4)\n","./dataset/vn_food/test/42.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(4)\n","./dataset/vn_food/test/2.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(4)\n","./dataset/vn_food/test/14.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(4)\n","./dataset/vn_food/test/50.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(4)\n","./dataset/vn_food/test/37.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(4)\n","./dataset/vn_food/test/387.png\n","<Figure size 640x480 with 1 Axes>\n","tensor(6)\n"],"name":"stdout"}]}]}